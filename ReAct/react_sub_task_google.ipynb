{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from colorama import Fore, Style, init\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Initialize colorama\n",
    "init()\n",
    "\n",
    "class FactChecker:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.tools_used = False\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        self.available_functions = {\n",
    "            \"call_google\": self.call_google,\n",
    "        }\n",
    "\n",
    "    def set_model(self, model_name):\n",
    "        \"\"\"更改模型\"\"\"\n",
    "        self.model = model_name\n",
    "    \n",
    "    def call_google(self, query, **kwargs):\n",
    "        try:\n",
    "            service = build(serviceName=\"customsearch\",\n",
    "                          version=\"v1\",\n",
    "                          developerKey=GOOGLE_API_KEY,\n",
    "                          static_discovery=False)\n",
    "            res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, **kwargs).execute()\n",
    "            res_items = res[\"items\"]\n",
    "            res_snippets = [r['snippet'] for r in res_items]\n",
    "            self.tools_used = True\n",
    "            return str(res_snippets)\n",
    "        except Exception as e:\n",
    "            print(Fore.RED + f\"Error: {str(e)}\")\n",
    "            print(Style.RESET_ALL)\n",
    "            return f\"Error in Google search: {str(e)}\"\n",
    "\n",
    "    def extract_sub_questions(self, article):\n",
    "        \"\"\"抽取子問題的prompt\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Please analyze the following article and break it down into 2-3 key factual claims \n",
    "        that need to be verified. Format them as numbered questions:\n",
    "        \n",
    "        Article: {article}\n",
    "        \n",
    "        Please list the sub-questions in this format:\n",
    "        1. [First question]\n",
    "        2. [Second question]\n",
    "        3. [Third question]\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at breaking down articles into key verifiable claims.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def verify_sub_question(self, sub_question, article):\n",
    "        \"\"\"驗證單個子問題\"\"\"\n",
    "        self.messages = []\n",
    "        self.tools_used = False\n",
    "        sys_prompt = \"\"\"\n",
    "        You are a fact-checking specialist. Verify the specific claim by:\n",
    "        1. Thinking about what you already know and what you need to verify\n",
    "        2. Use tool to find the information:\n",
    "            - call_google: For general information and recent events\n",
    "        3. Analyzing the search results\n",
    "        4. Providing a conclusion\n",
    "    \n",
    "        You must use this format:\n",
    "        Thought: [Your reasoning]\n",
    "        Action: [call_google]: [search query]\n",
    "    \n",
    "        After receiving an observation:\n",
    "        Thought: [Analysis combining your knowledge and the new information]\n",
    "        Action: [Another search if needed]\n",
    "        or\n",
    "        Answer: [Your final conclusion]\n",
    "    \n",
    "        Available actions:\n",
    "        call_google: [search term]\n",
    "        \"\"\"\n",
    "\n",
    "        user_prompt = f\"Sub-question: {sub_question}\\nArticle context: {article}\\n\\nPlease verify this claim using both your knowledge and external sources when needed.\"\n",
    "    \n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    \n",
    "        return self._run_verification_loop()\n",
    "\n",
    "    def _run_verification_loop(self):\n",
    "        action_re = re.compile('^Action: (\\w+): (.*)$')\n",
    "        answer_re = re.compile(\"Answer: \")\n",
    "        count = 0\n",
    "        last_answer = None  # 記錄最後一個有效的 Answer\n",
    "        \n",
    "        while True:\n",
    "            # 修改 messages 以適應 token 限制\n",
    "            self.messages = self.trim_messages_to_fit(self.messages, max_tokens=4096)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "            \n",
    "            response_msg = response.choices[0].message.content\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": response_msg})\n",
    "\n",
    "            # 嘗試提取 Answer\n",
    "            extracted_answer = self._extract_answer(response_msg)\n",
    "            if extracted_answer:\n",
    "                last_answer = extracted_answer  # 更新最後提取到的有效 Answer\n",
    "            \n",
    "            # 檢查工具是否被使用並有 Answer\n",
    "            if extracted_answer and self.tools_used:\n",
    "                print(Fore.YELLOW + response_msg)\n",
    "                print(Style.RESET_ALL)\n",
    "                return extracted_answer\n",
    "\n",
    "            # 如果有 Answer 但工具未被使用\n",
    "            elif extracted_answer:\n",
    "                print(Fore.YELLOW + \"Answer found but tool has not been used. Searching tools now.\")\n",
    "                print(Style.RESET_ALL)\n",
    "\n",
    "            print(Fore.GREEN + response_msg)\n",
    "            print(Style.RESET_ALL)\n",
    "            \n",
    "            # 處理回應中的 Action\n",
    "            actions = [action_re.match(a) for a in response_msg.split(\"\\n\") if action_re.match(a)]\n",
    "            if actions:\n",
    "                action, action_input = actions[0].groups()\n",
    "                try:\n",
    "                    print(Fore.CYAN + f\" -- running {action} {action_input}\")\n",
    "                    print(Style.RESET_ALL)\n",
    "                    \n",
    "                    observation = self.available_functions[action](action_input)\n",
    "                    self.tools_used = True\n",
    "                    \n",
    "                    if \"No claims found\" in observation:\n",
    "                        self.tools_used = False\n",
    "\n",
    "                    print(Fore.BLUE + f\"Observation: {observation}\")\n",
    "                    print(Style.RESET_ALL)\n",
    "                    self.messages.append({\"role\": \"user\", \"content\": \"Observation: \" + observation})\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(Fore.RED + f\"Error: {e}\")\n",
    "                    print(Style.RESET_ALL)\n",
    "                    continue\n",
    "            \n",
    "            # 沒有動作被檢測到\n",
    "            else:\n",
    "                count += 1\n",
    "                if count == 3:\n",
    "                    print(Fore.RED + \"No action is detected. The answer is Unknown.\")\n",
    "                    print(Style.RESET_ALL)\n",
    "                    \n",
    "                    # 如果有記錄到有效的 Answer\n",
    "                    if last_answer:\n",
    "                        print(Fore.GREEN + f\"Returning last extracted Answer: {last_answer}\")\n",
    "                        print(Style.RESET_ALL)\n",
    "                        return last_answer\n",
    "                    return \"Ignore this question\"\n",
    "                \n",
    "                print(Fore.RED + \"No action is detected. Continue...\")\n",
    "                self.tools_used = False\n",
    "                continue\n",
    "\n",
    "    def trim_messages_to_fit(self, messages, max_tokens=16385):\n",
    "        \"\"\"刪除前面的tokens以適應 token 限制\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(self.model)\n",
    "\n",
    "        # 如果第一條是 system prompt，暫時移除\n",
    "        system_message = None\n",
    "        if messages and messages[0][\"role\"] == \"system\":\n",
    "            system_message = messages.pop(0)\n",
    "\n",
    "        while self.count_tokens(messages) > max_tokens:\n",
    "            # 刪除最早的tokens，直到符合限制\n",
    "            messages.pop(0)\n",
    "\n",
    "        # 如果有 system prompt，重新插入到最前面\n",
    "        if system_message:\n",
    "            messages.insert(0, system_message)\n",
    "\n",
    "        return messages\n",
    "    \n",
    "    def count_tokens(self, messages, model=None):\n",
    "        \"\"\"計算 token 數\"\"\"\n",
    "        model = self.model \n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "        total_tokens = 0\n",
    "        for message in messages:\n",
    "            for key, value in message.items():\n",
    "                total_tokens += len(encoding.encode(value))\n",
    "        return total_tokens\n",
    "            \n",
    "    def _extract_answer(self, response_msg):\n",
    "        \"\"\"從回應中提取答案\"\"\"\n",
    "        lines = response_msg.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'Answer:' in line:\n",
    "                try:\n",
    "                    # 取 'Answer:' 後的內容\n",
    "                    answer = line.split('Answer:')[1].strip()\n",
    "                    print(f\"Extracted Answer: {answer}\")\n",
    "                    return answer\n",
    "                except IndexError as e:\n",
    "                    print(f\"Error extracting answer: {e}\")\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "\n",
    "    def _execute_action(self, action, action_input):\n",
    "        \"\"\"執行搜尋動作\"\"\"\n",
    "        if action in self.available_functions:\n",
    "            print(Fore.CYAN + f\" -- running {action} {action_input}\")\n",
    "            print(Style.RESET_ALL)\n",
    "            result = self.available_functions[action](action_input)\n",
    "            print(Fore.BLUE + f\"Observation: {result}\")\n",
    "            print(Style.RESET_ALL)\n",
    "            return result\n",
    "        else:\n",
    "            print(Fore.RED + f\"Unknown action: {action}\")\n",
    "            print(Style.RESET_ALL)\n",
    "            return f\"Unknown action: {action}\"\n",
    "                \n",
    "    def combine_results(self, results, article):\n",
    "        \"\"\"綜合所有子問題的結果\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Original article:\n",
    "        {article}\n",
    "\n",
    "        Based on the verification results of all sub-questions:\n",
    "        {results}\n",
    "    \n",
    "        Please provide a final conclusion about whether the article contains misleading information.\n",
    "        First provide your detailed reasoning, then end with either:\n",
    "        Final Answer: 1 (if misleading)\n",
    "        Final Answer: 0 (if accurate)\n",
    "        \"\"\"\n",
    "    \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a fact-checking expert providing final conclusions based on detailed analysis of multiple claims.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        # 印出組好的 Prompt\n",
    "        print(\"\\n=== Debug: Prompt for LLM ===\")\n",
    "        print(prompt)\n",
    "        print(\"=============================\")\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def verify_article(self, article):\n",
    "        \"\"\"主要驗證流程\"\"\"\n",
    "        print(Fore.CYAN + \"Extracting sub-questions...\" + Style.RESET_ALL)\n",
    "        sub_questions = self.extract_sub_questions(article)\n",
    "        print(Fore.YELLOW + \"Sub-questions extracted:\\n\" + sub_questions + Style.RESET_ALL)\n",
    "        \n",
    "        results = []\n",
    "        for q in sub_questions.split(\"\\n\"):\n",
    "            if q.strip() and q[0].isdigit():\n",
    "                print(Fore.CYAN + f\"\\nVerifying: {q}\" + Style.RESET_ALL)\n",
    "                result = self.verify_sub_question(q, article)\n",
    "                results.append(f\"Question: {q}\\nResult: {result}\")\n",
    "        \n",
    "        print(Fore.CYAN + \"\\nCombining results...\" + Style.RESET_ALL)\n",
    "        final_conclusion = self.combine_results(results, article)\n",
    "        print(Fore.YELLOW + \"\\nFinal conclusion:\\n\" + final_conclusion + Style.RESET_ALL)\n",
    "        \n",
    "        return final_conclusion\n",
    "    \n",
    "    def _clean_ansi_codes(self, text):\n",
    "        \"\"\"移除 ANSI 顏色代碼\"\"\"\n",
    "        ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "        return ansi_escape.sub('', text)\n",
    "    \n",
    "    def process_article_batch(self, input_file, output_file, num_files=None):\n",
    "        \"\"\"處理整個Excel中的文章\"\"\"\n",
    "        log_file = \"fact_checking_process.log\"\n",
    "        \n",
    "        try:\n",
    "            with open(log_file, 'w') as f:\n",
    "                try:\n",
    "                    df = pd.read_excel(input_file)\n",
    "                except UnicodeDecodeError:\n",
    "                    df = pd.read_excel(input_file)\n",
    "        \n",
    "                if num_files is not None:\n",
    "                    df_to_process = df.head(num_files)\n",
    "                else:\n",
    "                    df_to_process = df\n",
    "            \n",
    "                df['fact_check_response'] = ''\n",
    "                df['Simplified Answer'] = ''\n",
    "\n",
    "                df.to_excel(output_file, index=False)\n",
    "                print(\"開始處理文章...\")\n",
    "        \n",
    "                for idx, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Processing articles\"):\n",
    "                    \n",
    "                    # article = row['synthetic_misinformation']    # LLMFake \n",
    "                    article = row['text']   # mmsoc_gossipcop_text_labels-100 \n",
    "\n",
    "                    output_capture = io.StringIO()\n",
    "                    original_stdout = sys.stdout\n",
    "                    sys.stdout = output_capture\n",
    "\n",
    "                    try:\n",
    "                        result = self.verify_article(article)\n",
    "                    finally:\n",
    "                        sys.stdout = original_stdout\n",
    "\n",
    "                    detailed_output = output_capture.getvalue()\n",
    "                    cleaned_output = self._clean_ansi_codes(detailed_output)    \n",
    "                    simplified_answer = self._extract_simplified_answer(result)\n",
    "\n",
    "                    f.write(detailed_output)\n",
    "                    f.flush()\n",
    "\n",
    "                    current_df = pd.read_excel(output_file)\n",
    "\n",
    "                    current_df.at[idx, 'fact_check_response'] = cleaned_output\n",
    "                    current_df.at[idx, 'Simplified Answer'] = simplified_answer\n",
    "            \n",
    "                    current_df.to_excel(output_file, index=False)\n",
    "\n",
    "                print(f\"\\nAll articles processed. Results saved to {output_file}\", file=original_stdout)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\", file=original_stdout)\n",
    "            raise e\n",
    "  \n",
    "    def _extract_simplified_answer(self, response):\n",
    "        \"\"\"從回應中提取簡化的答案 (1 或 0)\"\"\"\n",
    "        try:\n",
    "            match = re.search(r\"Final Answer:\\s*(\\d)\", response)\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "        \n",
    "            digits = re.findall(r'[01]', response)\n",
    "            if digits:\n",
    "                return int(digits[-1])\n",
    "            else:\n",
    "                return \"Unknown\"\n",
    "        except Exception:\n",
    "            return \"Error\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始處理文章...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 0/120 [00:00<?, ?it/s]/tmp/ipykernel_1177325/1949283987.py:352: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Extracting sub-questions...\n",
      "Sub-questions extracted:\n",
      "1. Was Cher honored with the Billboard Icon Award at the 2017 Billboard Music Awards for her significant achievements in the music industry?\n",
      "2. Did Cher perform her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience?\n",
      "3. Did Cher deliver a speech after receiving the Billboard Icon Award, where she shared personal anecdotes and expressed gratitude, notably excluding any mention of Donald Trump?\n",
      "\n",
      "Verifying: 1. Was Cher honored with the Billboard Icon Award at the 2017 Billboard Music Awards for her significant achievements in the music industry?\n",
      "Thought: To verify if Cher was indeed honored with the Billboard Icon Award at the 2017 Billboard Music Awards, I can check official sources related to the event or reputable news articles reporting on the award recipients from that year. \n",
      "Action: call_google: 2017 Billboard Music Awards winners list \n",
      "\n",
      " -- running call_google 2017 Billboard Music Awards winners list \n",
      "\n",
      "Observation: ['The 2017 Billboard Music Awards ceremony was held at the T-Mobile Arena in Las Vegas, Nevada on May 21, 2017. The list of nominees was announced on April 10\\xa0...', 'May 21, 2017 ... More Stories by Billboard ... Drake was the big winner at the 2017 Billboard Music Awards. In fact, the rapper took home 13 awards, making him the\\xa0...', 'BTS Wins Top Social Artists- BBMA 2017 · BTS Wins Top Social Artist Intro - BBMA 2017 · Cher Accepts Icon Award - BBMA 2017 · Drake Wins Top Billboard Album -\\xa0...', 'May 21, 2017 ... Billboard Music Awards: Drake Wins Top Artist, Breaks Record for Most Wins in One Year. Beyonce, The Chainsmokers and Twenty-One Pilots also\\xa0...', 'May 22, 2017 ... Billboard Music Awards 2017: Complete Winners List · Top Artist: Drake Adele · Top New Artist: Zayn Alessia Cara · Billboard Chart Achievement\\xa0...', \"May 21, 2017 ... Drake was the big winner at the 2017 Billboard Music Awards, breaking Adele's record for the most awards in a year.\", 'Be the first to find out about GRAMMY nominees, winners, important news, and events. Privacy Policy. GRAMMYs. Advocacy.', \"May 21, 2017 ... Blake Shelton took home the night's biggest country music award at the 2017 Billboard Music Awards on Sunday night (May 21), winning Top\\xa0...\", 'Drake led the list of winners at the 2017 Billboard Music Awards. 8 years ago. Drake accepts the award for top male artist at the Billboard\\xa0...', \"May 2, 2017 ... From Camila Cabello to Bruno Mars, find out who's performing at the 2017 Billboard Music Awards.\"]\n",
      "\n",
      "Extracted Answer: Cher was indeed honored with the Billboard Icon Award at the 2017 Billboard Music Awards.\n",
      "Thought: The search results confirm that Cher did receive the Billboard Icon Award at the 2017 Billboard Music Awards. The source mentioning \"Cher Accepts Icon Award - BBMA 2017\" directly supports this claim, along with the event's official list of winners.\n",
      "Answer: Cher was indeed honored with the Billboard Icon Award at the 2017 Billboard Music Awards.\n",
      "\n",
      "\n",
      "Verifying: 2. Did Cher perform her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience?\n",
      "Thought: I need to verify whether Cher actually performed her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards and if the audience response was enthusiastic as claimed in the article.\n",
      "Action: call_google: Did Cher perform \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards?\n",
      "\n",
      " -- running call_google Did Cher perform \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards?\n",
      "\n",
      "Observation: ['May 21, 2017 ... ... performed her Hot 100-topping 1999 smash \"Believe ... If I Could Turn Back Time\\' Performance at the 2017 Billboard Music Awards.', 'May 22, 2017 ... Cher performed \"Believe\" and \"If I Could Turn Back Time\" before her powerful Icon Award acceptance speech at the Billboard Music Awards.', 'May 21, 2017 ... Cher stopped by the Billboard Music Awards to perform “Believe,” her 1999 megahit, as well as “If I Could Turn Back Time,” her classic from 10 years earlier.', 'May 21, 2017 ... ... Believe,” marking her first awards show performance in over 15 years. ... If I Could Turn Back Time.” Video Player is loading. Play Video.', 'May 21, 2017 ... The acclaimed singer received the prize, presented by Gwen Stefani, after performing “Believe” and “If I Could Turn Back Time.” For the latter\\xa0...', 'May 22, 2017 ... Cher performed hits \"If I Could Turn Back Time\" and \"Believe\" before receiving the Icon Award at the 2017 Billboard Music Awards.', '\"If I Could Turn Back Time\" is a song performed by American singer and ... Do You Believe? Tour (1999–2000); The Farewell Tour (2002–2005); Cher at the\\xa0...', 'May 21, 2017 ... first took the stage to perform 1998\\'s dance-pop hit \"Believe\" in a head-to-toe silver getup. ... perform \"If I Could Turn Back Time.\" She went\\xa0...', '... 2017. At the 2017 Billboard Music Awards, Cher performed \"Believe\" and \"If I Could Turn Back Time\", her first awards show performance in over 15 years.', 'May 21, 2017 ... Cher, who received the Icon award, sang her dance anthem \"Believe\" in ... rtx36xn0.jpg Cher performs \"If I Could Turn Back Time\" at the\\xa0...']\n",
      "\n",
      "Extracted Answer: The claim that Cher performed her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience, is verified as true based on the information found in multiple sources.\n",
      "Thought: Multiple sources confirm that Cher did perform her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards.\n",
      "Answer: The claim that Cher performed her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience, is verified as true based on the information found in multiple sources.\n",
      "\n",
      "\n",
      "Verifying: 3. Did Cher deliver a speech after receiving the Billboard Icon Award, where she shared personal anecdotes and expressed gratitude, notably excluding any mention of Donald Trump?\n",
      "Action: call_google: Did Cher mention Donald Trump in her 2017 Billboard Icon Award acceptance speech?\n",
      "\n",
      " -- running call_google Did Cher mention Donald Trump in her 2017 Billboard Icon Award acceptance speech?\n",
      "\n",
      "Observation: ['May 21, 2017 ... Cher delivered a heartfelt speech after performing two of her biggest hits when she accepted the Icon award at the Billboard Music Awards.', 'May 22, 2017 ... Accepting the Billboard Icon Award from singer Gwen Stefani, Cher ... of Trump, may say during her acceptance speech. Cher held back on\\xa0...', 'May 22, 2017 ... ... her powerful Icon Award acceptance speech at the Billboard Music Awards ... was going to be special,\" legendary artist said in Icon Award\\xa0...', 'May 4, 2017 ... ... mention, she was the first artist to have a No. 1 single on a ... my love of music with my fans,” Cher said in a statement. “Seeing so\\xa0...', 'May 21, 2017 ... Cher took home the \"Icon\" award at Sunday\\'s Billboard Music Awards and she didn\\'t mention President Trump ... Her speech was short and simple ...', 'Apr 24, 2024 ... In 2017, Cher was given the Icon Award at the Billboard Music Awards, followed by a Kennedy Center Honor in 2018. You can find her\\xa0...', 'Sep 17, 2017 ... ... accepting a Billboard Icon award, she credited most of her success to luck. In fact, she has spent more than 50 years in the public eye\\xa0...', 'May 21, 2017 ... ... that channeled Cher, who received the coveted ICON award at the show. ... In his acceptance speech for Top 200 Billboard album, the singer\\xa0...', \"Jun 30, 2021 ... 51 votes, 103 comments. She's the greatest female artist of all time. She is completely amazing. Her work is beyond incredible.\", 'May 22, 2017 ... ... Icon Award at the 2017 Billboard Music Awards ... Gwen Stefani was on hand to present Cher with the Icon Award following her performance.']\n",
      "\n",
      "Extracted Answer: The claim that Cher notably excluded any mention of Donald Trump in her 2017 Billboard Icon Award acceptance speech is verified as true.\n",
      "Thought: Several sources confirm that Cher did not mention Donald Trump in her 2017 Billboard Icon Award acceptance speech.\n",
      "Answer: The claim that Cher notably excluded any mention of Donald Trump in her 2017 Billboard Icon Award acceptance speech is verified as true.\n",
      "\n",
      "\n",
      "Combining results...\n",
      "\n",
      "=== Debug: Prompt for LLM ===\n",
      "\n",
      "        Original article:\n",
      "        Cher Steals the Show at the 2017 Billboard Music Awards This post is also available in: Français\n",
      "\n",
      "Cher reminded the world why she’s an icon at the 2017 Billboard Music Awards on Sunday night. With not one but two performances of her greatest hits and a Billboard Icon Award acceptance speech, she wowed the audience.\n",
      "\n",
      "“I think luck has so much to do with my success. I think it was mostly luck with a little bit of something thrown in,” Cher said as her son Chaz Bono watched from the audience.\n",
      "\n",
      "Cher joins an esteemed list of past award recipients, including Celine Dion, Prince, Jennifer Lopez, Stevie Wonder and Neil Diamond. With more than 100 million albums sold worldwide and a No. 1 single in every decade from the 1960s to the 2010s (she was the first artist to have a No. 1 single on a Billboard chart in each decade), Cher has certainly earned the honor of icon.\n",
      "\n",
      "Gwen Stefani presented Cher with the award, saying:\n",
      "\n",
      "“It is an honor for me to be here tonight to present the Billboard Icon Award to a woman who is truly the definition of the word icon: Cher. From the first note you know it’s her. Her artistry, her commitment to her craft and her willingness to take on new creative challenges have served as an inspiration to me and my career and she continues to inspire. She has proven that there is nothing she can not do. Cher is trailblazer, a fashion trendsetter, truly iconic looks at every single point in her career, a role model for preservering and showing us how to be strong and how to be true to ourselves. She is a cultural influencer, a tireless activist and an incredible humanitarian who cares about our world and speaks out against injustices.”\n",
      "\n",
      "Next, Cher performed her hits “Believe” and “If I Could Turn Back Time” that were electrifying and got the audience on their feet. For “Believe,” she donned a bleach blonde wig, barely-there dress made of glittery silver strands accented by heart-shaped pasties and silver boots.\n",
      "\n",
      "Cher also busted out a huge black curly wig, black leather jacket, thigh-high boots and sparkling black bodysuit for a performance of her 1989 smash “If I Could Turn Back Time.”\n",
      "\n",
      "After performing her hits, she accepted the Billboard Icon Award with a humble speech that notably left out any mention of Donald Trump.\n",
      "\n",
      "“So, I’ve wanted to do what I do since I was four years-old. And I’ve been doing it for 53 years. That is not an applause thing, I’m 71 yesterday. And I can do a five-minute plank, okay? Just saying. I want to thank my mom. Because when I was really young she said, ‘You’re not going to be the smartest, you’re not going to be the prettiest, you’re not going to be the most talented, but you’re going to be special.’ And when I met Sonny he said the same thing. There was really nothing about me that led anyone to believe that I was going to be special.”\n",
      "\n",
      "You’re more special than you know! And happy birthday, Cher!\n",
      "\n",
      "Watch Cher perform at the 2017 Billboard Music Awards:\n",
      "\n",
      "        Based on the verification results of all sub-questions:\n",
      "        ['Question: 1. Was Cher honored with the Billboard Icon Award at the 2017 Billboard Music Awards for her significant achievements in the music industry?\\nResult: Cher was indeed honored with the Billboard Icon Award at the 2017 Billboard Music Awards.', 'Question: 2. Did Cher perform her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience?\\nResult: The claim that Cher performed her hits \"Believe\" and \"If I Could Turn Back Time\" at the 2017 Billboard Music Awards, receiving an enthusiastic response from the audience, is verified as true based on the information found in multiple sources.', 'Question: 3. Did Cher deliver a speech after receiving the Billboard Icon Award, where she shared personal anecdotes and expressed gratitude, notably excluding any mention of Donald Trump?\\nResult: The claim that Cher notably excluded any mention of Donald Trump in her 2017 Billboard Icon Award acceptance speech is verified as true.']\n",
      "    \n",
      "        Please provide a final conclusion about whether the article contains misleading information.\n",
      "        First provide your detailed reasoning, then end with either:\n",
      "        Final Answer: 1 (if misleading)\n",
      "        Final Answer: 0 (if accurate)\n",
      "        \n",
      "=============================\n",
      "\n",
      "Final conclusion:\n",
      "Based on the detailed analysis of the claims presented in the original article and the verification results of all sub-questions, it is evident that the article accurately reports on Cher's accomplishments at the 2017 Billboard Music Awards. Cher was indeed honored with the Billboard Icon Award for her significant achievements in the music industry, performed her hits \"Believe\" and \"If I Could Turn Back Time\" to an enthusiastic audience response, and delivered a speech excluding any mention of Donald Trump. There is no evidence of misleading information in the article.\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "Final Answer: 0\n",
      "' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  current_df.at[idx, 'fact_check_response'] = cleaned_output\n",
      "Processing articles: 100%|██████████| 120/120 [49:30<00:00, 24.75s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All articles processed. Results saved to react_child_task_google_gossipcop-120.xlsx\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = \"gossipcop-120.xlsx\"  # if LLMFake file，revise above to synthetic_misinformation\n",
    "    output_file = \"react_child_task_google_gossipcop-120.xlsx\"\n",
    "    num_files_to_process = 120\n",
    "    \n",
    "    checker = FactChecker()\n",
    "    checker.set_model(\"gpt-3.5-turbo\")  # 設定使用的模型\n",
    "    \n",
    "    try:\n",
    "        checker.process_article_batch(input_file, output_file, num_files=num_files_to_process)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(Fore.RED + f\"Error in main execution: {str(e)}\" + Style.RESET_ALL)\n",
    "        return \"Error\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = FactChecker()\n",
    "checker.set_model(\"gpt-3.5-turbo\") # 設定使用的模型\n",
    "article = \"\"\"Chris Wattie / ReutersCanada warns immigrants in US about fleeing north Canada officials want to make it clear for would-be immigrants looking to cross the US-Canada border that they should do so legally.\"\"\"\n",
    "result = checker.verify_article(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檔案名稱: react_child_task_google_gossipcop-120.xlsx\n",
      "Accuracy: 0.6417\n",
      "F1 score: 0.6000\n",
      "label=1（假新聞）的準確率: 0.55, 錯誤數量: 9\n",
      "label=0（真新聞）的準確率: 0.66, 錯誤數量: 34\n",
      "Uncertain 的數量: 0\n",
      "ERROR 的數量: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = \"react_child_task_google_gossipcop-120\"\n",
    "\n",
    "data = pd.read_excel(f'{file_name}.xlsx')\n",
    "data['Simplified Answer'] = data['Simplified Answer'].astype(str)\n",
    "\n",
    "# 計算總體準確率（僅考慮 0 和 1）\n",
    "valid_predictions = data[data['Simplified Answer'].isin(['0', '1'])]\n",
    "overall_accuracy = (valid_predictions['label'] == valid_predictions['Simplified Answer'].astype(int)).mean()\n",
    "\n",
    "# 計算 label=1（假新聞）的準確率\n",
    "label_1_data = valid_predictions[valid_predictions['label'] == 1]\n",
    "accuracy_label_1 = (label_1_data['label'] == label_1_data['Simplified Answer'].astype(int)).mean()\n",
    "mistakes_label_1 = len(label_1_data) - (label_1_data['label'] == label_1_data['Simplified Answer'].astype(int)).sum()\n",
    "\n",
    "# 計算 label=0（真新聞）的準確率\n",
    "label_0_data = valid_predictions[valid_predictions['label'] == 0]\n",
    "accuracy_label_0 = (label_0_data['label'] == label_0_data['Simplified Answer'].astype(int)).mean()\n",
    "mistakes_label_0 = len(label_0_data) - (label_0_data['label'] == label_0_data['Simplified Answer'].astype(int)).sum()\n",
    "\n",
    "# 統計 \"Uncertain\" 和 \"error\" 的情況\n",
    "uncertain_count = len(data[data['Simplified Answer'] == 'Unknown'])\n",
    "error_count = len(data[data['Simplified Answer'] == 'ERROR'])\n",
    "\n",
    "# 計算f1 score\n",
    "f1_score = 2 * (accuracy_label_1 * accuracy_label_0) / (accuracy_label_1 + accuracy_label_0)\n",
    "\n",
    "print(f\"檔案名稱: {file_name}.xlsx\")\n",
    "print(f\"Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"F1 score: {f1_score:.4f}\")\n",
    "print(f\"label=1（假新聞）的準確率: {accuracy_label_1:.2f}, 錯誤數量: {mistakes_label_1}\")\n",
    "print(f\"label=0（真新聞）的準確率: {accuracy_label_0:.2f}, 錯誤數量: {mistakes_label_0}\")\n",
    "print(f\"Uncertain 的數量: {uncertain_count}\")\n",
    "print(f\"ERROR 的數量: {error_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
